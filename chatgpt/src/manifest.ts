import { Model } from "./type";

export const DEFAULT_MODEL: Model = {
    id: "openai/Qwen/Qwen2.5-72B-Instruct-Turbo",
    updated_at: "2024-10-24T12:28:19.875089",
    created_at: "2024-10-24T12:28:19.875090",
    name: "Default-Qwen2.5-72B",
    prompt: "",
    option: "openai/Qwen/Qwen2.5-72B-Instruct-Turbo",
    temperature: "1",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};

// export const QWEN2_5_72B: Model = {
//     id: "openai/Qwen/Qwen2.5-72B-Instruct-Turbo",
//     updated_at: "2024-10-24T13:06:13.397870",
//     created_at: "2024-10-24T13:06:13.397871",
//     name: "Qwen2.5-72B",
//     prompt: "",
//     option: "openai/Qwen/Qwen2.5-72B-Instruct-Turbo",
//     temperature: "0",
//     pinned: false,
//     vision: false,
//     base_url: "http://localhost:4000/v1",
// };

export const LMSTUDIO_LLAMA_1B: Model = {
    id: "openai/llama-3.2-1b-instruct",
    updated_at: "2024-10-24T13:06:13.397860",
    created_at: "2024-10-24T13:06:13.397868",
    name: "lmstudio-Llama-1B",
    prompt: "",
    option: "openai/llama-3.2-1b-instruct",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};

export const GPT_4O: Model = {
    id: "openai/gpt-4o",
    updated_at: "2024-10-24T13:06:13.397872",
    created_at: "2024-10-24T13:06:13.397873",
    name: "gpt-4o",
    prompt: "",
    option: "openai/gpt-4o",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const CLAUDE_3_5_SONNET: Model = {
    id: "openai/anthropic/claude-3.5-sonnet:beta",
    updated_at: "2024-10-24T13:06:13.397875",
    created_at: "2024-10-24T13:06:13.397875",
    name: "claude-3.5-sonnet",
    prompt: "",
    option: "openai/anthropic/claude-3.5-sonnet:beta",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LLAMA_3_1_405B: Model = {
    id: "openai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    updated_at: "2024-10-24T13:06:13.397876",
    created_at: "2024-10-24T13:06:13.397877",
    name: "Llama-3.1-405B",
    prompt: "",
    option: "openai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LLAMA_3_1_70B: Model = {
    id: "openai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    updated_at: "2024-10-24T13:06:13.397878",
    created_at: "2024-10-24T13:06:13.397879",
    name: "Llama-3.1-70B",
    prompt: "",
    option: "openai/meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const GEMMA_27B: Model = {
    id: "openai/google/gemma-2-27b-it",
    updated_at: "2024-10-24T13:06:13.397880",
    created_at: "2024-10-24T13:06:13.397881",
    name: "Gemma-27B",
    prompt: "",
    option: "openai/google/gemma-2-27b-it",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const MISTRAL: Model = {
    id: "openai/mistralai/Mistral-7B-Instruct-v0.1",
    updated_at: "2024-10-24T13:06:13.397884",
    created_at: "2024-10-24T13:06:13.397885",
    name: "Mistral",
    prompt: "",
    option: "openai/mistralai/Mistral-7B-Instruct-v0.1",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LMSTUDIO_QWEN2_5_14B_MLX: Model = {
    id: "openai/qwen2.5-14b",
    updated_at: "2024-10-24T13:06:13.397886",
    created_at: "2024-10-24T13:06:13.397887",
    name: "lmstudio-qwen2.5-14b-mlx",
    prompt: "",
    option: "openai/qwen2.5-14b",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LMSTUDIO_QWEN_14B: Model = {
    id: "openai/qwen2.5-14b-instruct",
    updated_at: "2024-10-24T13:06:13.397888",
    created_at: "2024-10-24T13:06:13.397889",
    name: "lmstudio-qwen-14B",
    prompt: "",
    option: "openai/qwen2.5-14b-instruct",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LMSTUDIO_NEMO: Model = {
    id: "openai/mistral-nemo-instruct-2407",
    updated_at: "2024-10-24T13:06:13.397890",
    created_at: "2024-10-24T13:06:13.397891",
    name: "lmstudio-nemo",
    prompt: "",
    option: "openai/mistral-nemo-instruct-2407",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const LMSTUDIO_LLAMA_3_2_3B_4BIT_MLX: Model = {
    id: "openai/llama-3.2-3b-instruct",
    updated_at: "2024-10-24T13:06:13.397892",
    created_at: "2024-10-24T13:06:13.397893",
    name: "lmstudio-Llama-3.2-3B-4bit-MLX",
    prompt: "",
    option: "openai/llama-3.2-3b-instruct",
    temperature: "0",
    pinned: false,
    vision: false,
    base_url: "http://localhost:4000/v1",
};


export const GPT_4O_MINI: Model = {
    id: "openai/gpt-4o-mini",
    updated_at: "2024-10-24T13:06:13.397894",
    created_at: "2024-10-24T13:06:13.397895",
    name: "gpt-4o-mini",
    prompt: "",
    option: "openai/gpt-4o-mini",
    temperature: "0",
    pinned: false,
    vision: true,
    base_url: "http://localhost:4000/v1",
};



export const MODEL_LIST: Model[] = [
    DEFAULT_MODEL,
    // QWEN2_5_72B,
    GPT_4O,
    CLAUDE_3_5_SONNET,
    LLAMA_3_1_405B,
    LLAMA_3_1_70B,
    GEMMA_27B,
    LMSTUDIO_LLAMA_1B,
    LMSTUDIO_QWEN2_5_14B_MLX,
    LMSTUDIO_QWEN_14B,
    LMSTUDIO_NEMO,
    LMSTUDIO_LLAMA_3_2_3B_4BIT_MLX,
    GPT_4O_MINI,
];
